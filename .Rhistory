x0 <-pm0$Sample.Value[25]
x0 <-pm0$Sample.Value
str(x0)
is.na(x0)
mean(is.na(x0))
pm1 <- make.names(cnames[[1]][wcol])
names(pm1) <- make.names(cnames[[1]][wcol])
dim(pm1)
x1 <- pm1$Sample
skip(0)
skip()
swirl()
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
dataset <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(dataset)
library(readr)
la_Universidad_Carlos_III_de_Madrid_completo <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(la_Universidad_Carlos_III_de_Madrid_completo)
bey()
library(readr)
la_Universidad_Carlos_III_de_Madrid_completo <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(la_Universidad_Carlos_III_de_Madrid_completo)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
setwd("~/Marieli")
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
setwd("~/Marieli")
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Marieli")
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
setwd("~/Marieli")
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
setwd("~/")
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
Madrid <- read_delim("Marieli/la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
dataset <- read_delim("la Universidad Carlos III de Madrid completo.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(dataset)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv",
+     ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Tecnopuc <- read_delim("Tecnopuc.csv", ";", escape_double = FALSE, trim_ws = TRUE)
View(Madrid)
colnames(Madrid)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Tecnopuc <- read_delim("Tecnopuc.csv", ";", escape_double = FALSE, trim_ws = TRUE)
library(dplyr)
DataKruskal <- c(Madrid$)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Tecnopuc <- read_delim("Tecnopuc.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Madrid$Valor
Madrid$valor
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Tecnopuc <- read_delim("Tecnopuc.csv", ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
setwd("~/")
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Madrid <- read_delim("la Universidad Carlos III de Madrid completo.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Tecnopuc <- read_delim("Tecnopuc.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Madrid$valor
kruskal.test(Madrid$valor ~ Tecnopuc$valor)
summary(Madrid$valor)
Summary(Tecnopuc$valor)
summary(Madrid$valor)
Summary(Tecnopuc$valor)
summary(Madrid$valor)
Summary(Tecnopuc$valor)
summary(Madrid$valor)
Summary(Tecnopuc$valor)
library(dplyr)
summary(Madrid$valor)
library(dplyr)
summary(Madrid$valor)
summary(Tecnopuc$valor)
kruskal.test(Madrid$valor ~ Tecnopuc$valor)
kruskal.test(Madrid$valor,Tecnopuc$valor)
unlink('Marieli/Kruskal_cache', recursive = TRUE)
knit_with_parameters('~/Marieli/Kruskal.Rmd', encoding = 'UTF-8')
library(sp)
setwd("~/")
knit_with_parameters('~/Kruskal.Rmd', encoding = 'UTF-8')
setwd("~/")
bookdown:::serve_book()
library(sp)
install.packages(sp)
remove.packages("sp", lib="~/R/win-library/3.5")
install.packages("C:/Users/Jacob/Downloads/sp-master.zip", repos = NULL, type = "win.binary")
library(lib)
install.packages("C:/Users/Jacob/Downloads/sp-master.zip", repos = NULL, type = "win.binary")
install.packages("sp")
library(sp)
library(spatial, lib.loc = "C:/Program Files/Microsoft/R Open/R-3.5.2/library")
library(knitr)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/Kruskal.Rmd', encoding = 'UTF-8')
setwd("~/")
install.packages("rsconnect")
install.packages("reader")
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
library(swirl)
install_from_swirl("Regression Models")
swirl()
0
bey()
bey
skip()
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lw=3, col='red')
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
fit$residuals
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coefficients[1]
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
skip()
all.equal(lhs,rhs)
varChild <- var(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(ols.slope, ols.ic)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, sum(varRes,varRes))
all.equal(varChild, varRes+varRes)
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit)
mean(efit$residuals)
cov(attenu$mag)
cov(efit$residuals ~ attenu$mag)
skyp()
skip()
cov(efit$residuals, attenu$dist)
swirl()
install.packages("rmarkdown")
library(markdown)
install.packages("knitr")
install.packages("Rtools")
install.packages("Miktex")
install.packages("Rtool")
install.packages("~/Rtools35.exe", repos = NULL)
library(sp)
install.packages("Rtools")
install.packages("~/Rtools35.exe", repos = NULL)
install.packages("repo")
install.packages("~/Rtools35.exe", repos = NULL)
install.packages("Rtools")
library(Rtools)
install.packages("~/Rtools35.exe", repos = NULL)
install.packages("Rtools", repos = NULL, type="source")
unlink('teste_cache', recursive = TRUE)
knit_with_parameters('~/Untitled/teste 4.Rmd')
install.packages("latexpdf")
swirl()
library(swirl)
swirl()
simbias <- function(seed=8765){
# The default seed guarantees a nice histogram. This is the only1
# reason that accepting the default, x1c <- simbias(), is required in the lesson.
# The effect will be evident with other seeds as well.
set.seed(seed)
temp <- rnorm(100)
# Point A
x1 <- (temp + rnorm(100))/sqrt(2)
x2 <- (temp + rnorm(100))/sqrt(2)
x3 <- rnorm(100)
# Function to simulate regression of y on 2 variables.
f <- function(k){
# Point B
y <- x1 + x2 + x3 + .3*rnorm(100)
# Point C
c(lm(y ~ x1 + x2)$coef[2],
lm(y ~ x1 + x3)$coef[2])
}
# Point D
sapply(1:150, f)
}
# Illustrate the effect of bogus regressors on residual squared error.
bogus <- function(){
temp <- swiss
# Add 41 columns of random regressors to a copy of the swiss data.
for(n in 1:41){temp[,paste0("random",n)] <- rnorm(nrow(temp))}
# Define a function to compute the deviance of Fertility regressed
# on all regressors up to column n. The function, deviance(model), computes
# the residual sum of squares of the model given as its argument.
f <- function(n){deviance(lm(Fertility ~ ., temp[,1:n]))}
# Apply f to data from n=6, i.e., the legitimate regressors,
# through n=47, i.e., a full complement of bogus regressors.
rss <- sapply(6:47, f)
# Display result.
plot(0:41, rss, xlab="Number of bogus regressors.", ylab="Residual squared error.",
main="Residual Squared Error for Swiss Data\nUsing Irrelevant (Bogus) Regressors",
pch=21, bg='red')
}
plot(0:41, rss, xlab="Number of bogus regressors.", ylab="Residual squared error.",
+        main="Residual Squared Error for Swiss Data\nUsing Irrelevant (Bogus) Regressors",
+        pch=21, bg='red')
plot(0:41, rss, xlab="Number of bogus regressors.", ylab="Residual squared error.", main="Residual Squared Error for Swiss Data\nUsing Irrelevant (Bogus) Regressors", pch=21, bg='red')
install.packages("latex2exp")
library("knitr", lib.loc="~/R/win-library/3.5")
install.packages("knitLatex")
library("knitr", lib.loc="~/R/win-library/3.5")
detach("package:knitr", unload=TRUE)
library("knitr", lib.loc="~/R/win-library/3.5")
detach("package:knitr", unload=TRUE)
install.packages("knitr")
library("knitLatex", lib.loc="~/R/win-library/3.5")
library("knitr", lib.loc="~/R/win-library/3.5")
detach("package:knitLatex", unload=TRUE)
detach("package:knitr", unload=TRUE)
install.packages("bookdown")
install.packages("tufte")
library("sp", lib.loc="~/R/win-library/3.5")
install.packages("rattle")
install.packages("randomForest")
library("sp", lib.loc="~/R/win-library/3.5")
detach("package:sp", unload=TRUE)
library("sp", lib.loc="~/R/win-library/3.5")
install.packages("sp")
library("sp", lib.loc="~/R/win-library/3.3")
install.packages("tm")
install.packages("wordcloud")
install.packages("textreadr")
install.packages("tidytext")
install.packages("igraph")
g <- graph.adjacency(m, mode = "undirected", weighted=TRUE)
plot(g)
tkplot(g)
g <- graph.adjacency(frequenciaPalavras, mode = "undirected", weighted=TRUE)
plot(g)
tkplot(g)
install.packages("ggraph")
frequenciaPalavras %>%
filter(n >= 30) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_node_point(color = "darkslategray4", size = 3) +
geom_node_text(color = "red", aes(label = name), vjust = 1.8, size=3) +
labs(title= "Grafo de Palavras",
subtitle = "Text mining de dados do GPO",
x = "", y = "")
install.packages("ggplot2")
frequenciaPalavras %>%
filter(n >= 100) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n)) +
geom_node_point(color = "darkslategray4", size = 3) +
geom_node_text(color = "red", aes(label = name), vjust = 1.8, size=3) +
labs(title= "Grafo de Palavras",
subtitle = "Text mining de dados do GPO",
x = "", y = "")
# Lista de palavras para remover
palavrasRemover <- c(stopwords(kind = "en"), letters) %>%
as.tibble() %>%
rename(Palavra = value) %>%
mutate(Palavra = NormalizaParaTextMining(Palavra))
# Arquivo pdf
arquivoPdf <- "https://www.govinfo.gov/content/pkg/GPO-OILCOMMISSION/pdf/GPO-OILCOMMISSION.pdf"
# Cria tabela com palavras e frequencias
frequenciaPalavras <- arquivoPdf %>%
read_pdf() %>%
as.tibble() %>%
select(text) %>%
unnest_tokens(Palavra, text) %>%
mutate(Palavra = NormalizaParaTextMining(Palavra)) %>%
anti_join(palavrasRemover) %>%
count(Palavra, sort = TRUE) %>%
filter(Palavra != "")
# Visualiza frequencia de palavras
frequenciaPalavras
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(tidyverse) # Manipulacao eficiente de dados
library(tidytext) # Manipulacao eficiente de texto
library(textreadr) # Leitura de pdf para texto
library(tm) # Pacote de mineracao de texto com stopwords
library(wordcloud) # Grafico nuvem de palavras
library(igraph)
library(ggraph)
library(ggplot2)
library(dplyr)
# Função para normalizar texto
NormalizaParaTextMining <- function(texto){
# Normaliza texto
texto %>%
chartr(
old = "áéíóúÁÉÍÓÚýÝàèìòùÀÈÌÒÙâêîôûÂÊÎÔÛãõÃÕñÑäëïöüÄËÏÖÜÿçÇ´`^~¨:.!?&$@#0123456789",
new = "aeiouAEIOUyYaeiouAEIOUaeiouAEIOUaoAOnNaeiouAEIOUycC                       ",
x = .) %>% # Elimina acentos e caracteres desnecessarios
str_squish() %>% # Elimina espacos excedentes
tolower() %>% # Converte para minusculo
return() # Retorno da funcao
}
# Lista de palavras para remover
palavrasRemover <- c(stopwords(kind = "en"), letters) %>%
as.tibble() %>%
rename(Palavra = value) %>%
mutate(Palavra = NormalizaParaTextMining(Palavra))
# Arquivo pdf
arquivoPdf <- "https://www.govinfo.gov/content/pkg/GPO-OILCOMMISSION/pdf/GPO-OILCOMMISSION.pdf"
# Cria tabela com palavras e frequencias
frequenciaPalavras <- arquivoPdf %>%
read_pdf() %>%
as.tibble() %>%
select(text) %>%
unnest_tokens(Palavra, text) %>%
mutate(Palavra = NormalizaParaTextMining(Palavra)) %>%
anti_join(palavrasRemover) %>%
count(Palavra, sort = TRUE) %>%
filter(Palavra != "")
# Visualiza frequencia de palavras
frequenciaPalavras
library(widyr)
# we need to filter for at least relatively common words first
word_cor <- par_Palavras %>%
group_by(word1) %>%
filter(n() >= 5) %>%
widyr::pairwise_cor(word1,word2, sort = TRUE)
licence()
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(Visual_Bias)
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
DT::datatable(Visual_Bias)
# find detailed in 'Special functions' section of ?select.
#
# 2. gather() all columns EXCEPT score_range, using
# key = part_sex and value = count.
#
# 3. separate() part_sex into two separate variables (columns),
# called "part" and "sex", respectively. You may need to check
# the 'Examples' section of ?separate to remember how the 'into'
# argument should be phrased.
#
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
print
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
DT::datatable(Visual_Bias)
aggregate(Candidato ~ variaveis, Visual_Bias, var)
aggregate(Candidatos ~ variaveis, Visual_Bias, var)
Tidy1 <- aggregate(Candidatos ~ variaveis, Visual_Bias, var)
DT::datatable(Tidy1)
# Pacotes e Funções
library(tidyverse) # Manipulacao eficiente de dados
library(igraph)
library(ggraph)
library(ggplot2)
library(dplyr)
library(pdftools)
library(RRPP)
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
DT::datatable(Visual_Bias)
Tidy1 <- aggregate(Candidatos ~ variaveis, Visual_Bias, var)
DT::datatable(Tidy1)
library(readxl)
Tidy1 <- read_excel("ANOVA/Tidy1.xlsx")
View(Tidy1)
library(readxl)
Tidy1 <- read_excel("ANOVA/Tidy1.xlsx")
DT::datatable(Tidy1)
aggregate(Candidatos ~ Variaveis, Tidy1, var)
library(readxl)
Tidy1 <- read_excel("ANOVA/Tidy1.xlsx")
DT::datatable(Tidy1)
aggregate(Candidatos ~ Variaveis, Tidy1, var)
aggregate(Variaveis ~ Candidatos, Tidy1, var)
bartlett.test(Variaveis ~ Candidatos, Tidy1)
tab.anova2 <- aov(Tidy1$Variaveis ~ Tidy1$Candidatos)
summary(tab.anova2)
tab.anova2 <- aov(Tidy1$Variaveis ~ Tidy1$Candidatos)
summary(tab.anova2)
AnovaAOV <- aov(Tidy1$Variaveis ~ Tidy1$Candidatos)
summary(AnovaAOV)
AnovaLM <- lm(Variaveis ~ Candidatos, data= Tidy1)
summary(modelo.anova)
AnovaAOV <- aov(Tidy1$Variaveis ~ Tidy1$Candidatos)
summary(AnovaAOV)
AnovaLinearModel <- lm(Variaveis ~ Candidatos, data= Tidy1)
summary(AnovaLinearModel)
library(readr)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
DT::datatable(Visual_Bias)
library(readxl)
Tidy1 <- read_excel("ANOVA/Tidy1.xlsx")
DT::datatable(Tidy1)
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ Candidato, data= Tidy1)
summary(AnovaLinearModel)
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ ., data= Tidy1)
summary(AnovaLinearModel)
AnovaLinearModel <- lm(VB ~ ., data= Tidy1)
summary(AnovaLinearModel)
AnovaLinearModel <- lm(VB ~ ., data= Tidy1)
summary(lm(AnovaLinearModel)
)
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ . + Candidato, data= Tidy1)
summary(lm(AnovaLinearModel))
summary(lm(Fertility ~ Agriculture, swiss))
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ . + Candidato, data= Tidy1)
summary(lm(AnovaLinearModel))
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ Candidato -1, data= Tidy1)
summary(lm(AnovaLinearModel))
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
summary(AnovaAOV)
AnovaLinearModel <- lm(VB ~ Candidato -1, data= Tidy1)
summary(AnovaLinearModel)
DT::datatable(aggregate(VB ~ Candidato, Tidy1, var))
aggregate(VB ~ Candidato, Tidy1, var)
DT::datatable(bartlett.test(VB ~ Candidato, Tidy1))
AnovaAOV <- aov(Tidy1$VB ~ Tidy1$Candidato)
DT::datatable(summary(AnovaAOV))
AnovaLinearModel <- lm(VB ~ Candidato -1, data= Tidy1)
DT::datatable(summary(AnovaLinearModel))
AnovaLinearModel <- lm(VB ~ Candidato -1, data= Tidy1)
summary(AnovaLinearModel)
anova(AnovaAOV)
anova(AnovaLinearModel)
plot(AnovaAOV)
plot(anova(AnovaAOV))
plot(anova(AnovaLinearModel))
plot(AnovaAOV)
setwd("~/ANOVA")
# Pacotes e Funções
library(tidyverse) # Manipulacao eficiente de dados
library(igraph)
library(ggraph)
library(ggplot2)
library(dplyr)
library(pdftools)
plot(AnovaAOV)
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
DT::datatable(Visual_Bias)
setwd("~/ANOVA")
library(readr)
setwd("~/ANOVA")
Visual_Bias <- read_delim("ANOVA/Visual_Bias.csv", ";", escape_double = FALSE, trim_ws = TRUE)
Visual_Bias
